# Projeto: Subset Sum (Soma de Subconjuntos)
**Disciplina:** Teoria da Computa√ß√£o | **Institui√ß√£o:** CESAR School

Este reposit√≥rio cont√©m a implementa√ß√£o e an√°lise de complexidade do algoritmo **Subset Sum** (Soma de Subconjuntos), desenvolvido em **Python** e **Java** para fins de compara√ß√£o de desempenho e efici√™ncia algor√≠tmica.

---

## 1. O Que √© o Problema?

### Explica√ß√£o Intuitiva (Analogia do Troco)
Imagine que voc√™ tem algumas notas de dinheiro no bolso (ex: R$ 2, R$ 5, R$ 10) e quer saber se consegue pagar uma conta de exatamente R$ 7 sem precisar de troco.
- **Entrada:** Suas notas `[2, 5, 10]` e o alvo `7`.
- **L√≥gica:** Testar combina√ß√µes. A nota de 2 sozinha n√£o d√°. A de 5 sozinha n√£o d√°. Mas `2 + 5 = 7`.
- **Sa√≠da:** `Verdadeiro` (Sim, √© poss√≠vel).

### Defini√ß√£o Formal
Dado um conjunto de n√∫meros inteiros n√£o-negativos e um valor alvo (*target*), o objetivo √© determinar se existe algum subconjunto desses n√∫meros cuja soma seja exatamente igual ao alvo.

---

## 2. Como Resolvemos (O Algoritmo)

Utilizamos a t√©cnica de **Programa√ß√£o Din√¢mica**. Em vez de for√ßa bruta (testar todas as combina√ß√µes, o que seria exponencial $O(2^N)$), criamos uma "tabela de verdades".

### L√≥gica Implementada
1. Criamos um vetor booleano `dp` de tamanho `target + 1`.
2. A posi√ß√£o `dp[i]` indica se a soma `i` √© poss√≠vel.
3. Come√ßamos com `dp[0] = True` (soma zero √© sempre poss√≠vel: basta n√£o escolher nada).
4. Para cada n√∫mero `x` da nossa lista, percorremos o vetor `dp`. Se a soma `j - x` j√° era poss√≠vel antes, ent√£o a soma `j` agora tamb√©m √© poss√≠vel.

### Pseudoc√≥digo
```text
Fun√ß√£o SubsetSum(arr, target):
    Criar vetor dp[target + 1] inicializado como Falso
    dp[0] = Verdadeiro

    Para cada numero x em arr:
        Para j de target at√© x (decrescente):
```

## 3. An√°lise de Complexidade

A efici√™ncia deste algoritmo depende n√£o apenas da quantidade de n√∫meros, mas tamb√©m do valor da soma alvo (*target*).

### ‚è±Ô∏è Complexidade de Tempo
Nossa implementa√ß√£o percorre todos os n√∫meros e, para cada um, atualiza a tabela at√© o valor do *target*.
- **Pior Caso (Big-O):** $O(N \cdot S)$
- **Melhor Caso (Big-Œ©):** $\Omega(N \cdot S)$
- **Caso M√©dio (Big-Œò):** $\Theta(N \cdot S)$

> **Onde:**
> - $N$ = Quantidade de elementos no conjunto.
> - $S$ = Valor da soma alvo (*target*).

### üíæ Complexidade de Espa√ßo
Utilizamos um vetor unidimensional para armazenar os resultados parciais.
- **Espa√ßo:** $O(S)$ (Proporcional ao valor do *target*).

---

## 4. Resultados Experimentais e Compara√ß√£o (Python vs Java)

Realizamos experimentos com entradas de tamanhos variados (N=25 a N=10.000) executando cada teste 15 vezes para obter a m√©dia precisa e desvio padr√£o.

### üß™ Metodologia Rigorosa
Para garantir a integridade dos dados, **a medi√ß√£o do tempo em Java foi realizada internamente (System.nanoTime)**, excluindo o tempo de inicializa√ß√£o da M√°quina Virtual Java (JVM/Warm-up). Isso garante que estamos comparando apenas a efici√™ncia do algoritmo, e n√£o o tempo de carga da linguagem.

### üìä An√°lise dos Resultados
Observamos um fen√¥meno interessante onde a implementa√ß√£o em **Python (com NumPy)** superou o **Java** nos casos m√©dios e grandes.

![Gr√°fico Comparativo](comparacao_tempos.png)
*(Gr√°fico 1: Compara√ß√£o direta de tempos de execu√ß√£o)*

1.  **Pequeno (N=25):** Ambas as linguagens s√£o instant√¢neas (~0.03ms no Java), provando que o overhead de execu√ß√£o √© desprez√≠vel e a medi√ß√£o est√° correta.
2.  **M√©dio e Grande:** O Python foi cerca de **3x mais r√°pido** que o Java.

### üí° Por que o Python ganhou?
Embora Python seja geralmente mais lento que Java, nossa implementa√ß√£o utilizou a biblioteca **NumPy**.
- **Python (Vetorizado):** A linha `dp[x:] |= dp[:-x]` realiza opera√ß√µes *bitwise* em bloco (vetoriza√ß√£o), processando 64 bits (ou mais) por ciclo de CPU diretamente em C.
- **Java (Loops):** A implementa√ß√£o utilizou loops expl√≠citos. O Java precisa iterar posi√ß√£o por posi√ß√£o do vetor booleano, realizando muito mais opera√ß√µes de CPU para fazer o mesmo trabalho.
- **Conclus√£o:** A "vit√≥ria" do Python deve-se √† otimiza√ß√£o de baixo n√≠vel do NumPy, que efetivamente divide a constante de tempo por um fator relacionado ao tamanho da palavra do processador (ex: 64).

### üìà Valida√ß√£o da Complexidade Te√≥rica
O gr√°fico abaixo compara os tempos medidos com a curva te√≥rica $O(N \cdot S)$.

![Curva de Complexidade](curva_complexidade.png)
*(Gr√°fico 2: Curva Te√≥rica vs Pr√°tica)*

A curva laranja (Java) alinha-se perfeitamente com a curva pontilhada cinza (Te√≥rica), validando experimentalmente que o algoritmo √© de fato $O(N \cdot S)$.

---

## 5. Discuss√£o sobre a Aplicabilidade Pr√°tica

Este algoritmo √© eficiente quando o valor da soma alvo ($S$) e o n√∫mero de elementos ($N$) s√£o pequenos ou moderados.

### ‚úÖ Contextos Favor√°veis
- **Problemas de Troco:** Verificar se √© poss√≠vel dar um troco exato.
- **Particionamento de Conjuntos:** Dividir recursos ou tarefas de valores baixos de forma equitativa.
- **Transa√ß√µes Financeiras:** Concilia√ß√£o banc√°ria onde se busca quais transa√ß√µes somam um valor espec√≠fico.

### ‚ùå Contextos Ineficientes
Se o alvo $S$ for muito grande (ex: $10^9$), o vetor `dp` consumir√° muita mem√≥ria e o tempo de execu√ß√£o ser√° proibitivo, mesmo que $N$ seja pequeno. Isso ocorre porque a complexidade depende do valor num√©rico.

---

## 6. An√°lise de Casos (Melhor, Pior e M√©dio)

A performance do algoritmo varia pouco devido √† natureza da implementa√ß√£o baseada em preenchimento completo da tabela.

- **Pior Caso:** $O(N \cdot S)$
  - Ocorre sempre, pois nesta implementa√ß√£o percorremos toda a tabela sem otimiza√ß√µes de parada antecipada.
- **Melhor Caso:** $O(N \cdot S)$
  - Mesmo que o alvo seja encontrado cedo, o c√≥digo continua preenchendo a tabela (para manter a simplicidade did√°tica e uso do NumPy). Portanto, o tempo √© consistente.
- **Caso M√©dio:** $O(N \cdot S)$
  - Segue a mesma l√≥gica, pois a estrutura dos la√ßos √© fixa e independente da sorte na distribui√ß√£o dos n√∫meros.

---

## 7. Reflex√£o Final (Classe P vs NP)

O problema **Subset Sum** pertence √† classe **NP-Completo**.

### ‚ùì √â classe P?
**N√£o se sabe.** Se $P \neq NP$ (a conjectura mais aceita na ci√™ncia da computa√ß√£o), ent√£o n√£o existe algoritmo que resolva este problema em tempo polinomial em rela√ß√£o ao *tamanho da entrada em bits*.

### üöÄ Por que a solu√ß√£o parece r√°pida?
A solu√ß√£o apresentada √© **Pseudo-Polinomial**.
- Ela √© polinomial em rela√ß√£o ao *valor num√©rico* da soma ($S$).
- Por√©m, √© exponencial em rela√ß√£o ao *n√∫mero de bits* necess√°rios para representar $S$. Se dobrarmos o n√∫mero de bits do target (por exemplo, de 1 milh√£o para 1 trilh√£o), o tempo de execu√ß√£o aumenta drasticamente, tornando-a invi√°vel.

### üîó Contexto Te√≥rico
- **Vers√£o NP:** A vers√£o de decis√£o ("existe um subconjunto?") √© a que define a classe NP-Completo.
- **Problemas Semelhantes:**
  - **Problema da Mochila (Knapsack Problem).**
  - **Problema da Parti√ß√£o (Partition Problem).**
